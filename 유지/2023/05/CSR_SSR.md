# CSR과 SSR

## CSR

CSR은 웹 애플리케이션의 클라이언트(브라우저)에서 페이지를 렌더링하는 방법입니다.
CSR에서는 웹 서버에서 클라이언트로 전달되는 HTML, CSS, JS등의 리소스를 사용하여 클라이언트 측에서 페이지를 렌더링합니다.
이 방법은 초기 로딩 속도가 느리지만, 로딩 후에는 클라이언트에서 자원을 관리하므로 사용자 경험이 더욱 원활해집니다. CSR은 React, Angular, Vue.js와 같은 프론트엔드 프레임워크에서 주로 사용됩니다.

## SSR

SSR은 웹 애플리케이션의 서버 측에서 페이지를 렌더링하는 방법입니다.
SSR에서는 서버에서 페이지를 렌더링하고, 클라이언트로 전달할 때는 미리 렌더링된 HTML 코드를 전송합니다.
이 방법은 초기 로딩 속도가 빠르지만, 서버에서 자원을 관리하기 때문에 초기 비용이 높습니다.
SSR은 Next.js, Nuxt.js와 같은 프레임워크에서 주로 사용됩니다.

### 왜 SSR 방식을 사용하면 SEO가 가능해질까?

SSR 방식은 서버 측에서 페이지를 렌더링하기 때문에, 클라이언트 측에서 JavaScript를 실행하지 않고도 HTML을 생성할 수 있습니다.
이로 인해서 검색 엔진에서 페이지의 콘텐츠를 분석할 때 페이지 내용을 더 잘 읽을 수 있습니다.
반면에 CSR 방식은 클라이언트 측에서 JavaScript를 실행하여 페이지를 렌더링하기 때문에, 검색 엔진은 JavaScript를 실행하지 못하고 페이지의 콘텐츠를 인식하지 못할 수 있습니다.
이로 인해서 검색 엔진 최적화(SEO)에 부정적인 영향을 미칠 수 있습니다.
또한, SSR 방식에서는 서버에서 생성된 HTML을 브라우저로 보내는 것이므로, 초기 로딩 속도가 빠릅니다.
이는 검색 엔진에서도 페이지의 로딩 속도가 빠르다고 인식하여, 검색 순위에서 더 높은 가치를 부여할 수 있습니다.

## SEO

SEO(Search Engine Optimization)는 검색 엔진에서 웹 페이지를 검색하고 순위를 매기는 방식을 이해하고, 이를 최적화하여 검색 결과에서 상위에 노출되도록 하는 기술입니다.

### SEO는 어떤 원리로 이루어질까?

검색 엔진은 크게 크롤링(crawling), 색인(indexing), 순위 매기기(ranking)의 세 단계로 이루어집니다.

1. 크롤링: 검색 엔진이 인터넷을 순회하며 웹 페이지를 발견하고 수집하는 과정입니다. 이 과정에서 검색 엔진은 웹 페이지의 HTML 코드와 링크를 수집합니다.
2. 색인: 검색 엔진이 수집한 웹 페이지를 분석하여 인덱스에 등록하는 과정입니다. 이 과정에서 검색 엔진은 웹 페이지의 콘텐츠, 제목, 메타 태그 등을 분석하여 웹 페이지의 주제와 내용을 이해합니다.
3. 순위 매기기: 검색 엔진은 색인된 웹 페이지를 검색어에 따라 순위를 매기는 과정입니다. 이 과정에서 검색 엔진은 수많은 알고리즘과 머신 러닝 기술을 활용하여, 사용자에게 가장 유용하다고 판단되는 웹 페이지를 상위에 노출합니다.
   따라서, SEO를 위해서는 검색 엔진이 쉽게 웹 페이지를 수집하고 분석할 수 있도록 웹 페이지의 구조, 콘텐츠, 메타 데이터 등을 최적화해야 합니다. 또한, 검색 엔진의 알고리즘에 맞게 검색어를 선택하고, 사용자 경험을 개선하는 방법 등을 고려하여, 상위 노출을 위한 최적화를 수행해야 합니다.

---

이미지 최적화, 메타 태그를 제외하고도 Next.js에서는 개발자가 SEO를 고려했을 때 할 수 있는 추가 작업이 있습니다.

1. `<Head>`컴포넌트를 활용하여 메타 데이터 추가하기
   Next.js에서는 `<Head>`컴포넌트를 사용하여 웹 페이지의 메타 데이터를 추가할 수 있습니다. 이를 통해 웹 페이지의 제목, 설명, 키워드 등을 검색 엔진이 인식할 수 있도록 최적화할 수 있습니다.
2. 동적 라우팅을 위한 `getStaticPaths`메소드 사용하기
   Next.js에서 동적 라우팅을 위해 사용되는 `getStaticPaths`메소드는 웹 페이지를 미리 생성하여 정적 페이지로 사용하는 SSG(Static Site Generation) 기능에서 사용됩니다. 이를 활용하여 검색 엔진이 동적 페이지에 접근할 수 있도록 미리 생성된 정적 페이지를 제공할 수 있습니다.
3. `getServerSideProps`메소드 사용하기
   SSR 기능을 사용할 때, `getServerSideProps`메소드를 사용하여 웹 페이지의 데이터를 서버 측에서 미리 불러와 렌더링할 수 있습니다. 이를 통해 검색 엔진이 웹 페이지의 콘텐츠를 더 잘 인식할 수 있도록 할 수 있습니다.
4. 검색 엔진 크롤링을 위한 robots.txt
   Next.js 프로젝트에서는 검색 엔진 크롤링을 제어하는 `robots.txt`파일을 설정할 수 있습니다. 이를 활용하여 검색 엔진이 수집해야 하는 페이지와 제외해야 하는 페이지를 명시할 수 있습니다.
5. CDN을 활용하여 웹 페이지 로딩 속도 개선하기
   Next.js에서는 정적 리소스를 CDN(Content Delivery Network)을 활용하여 로딩 속도를 개선할 수 있습니다. 이를 통해 검색 엔진이 웹 페이지의 로딩 속도를 더 빠르게 인식할 수 있도록 할 수 있습니다.

---

#### 느낀점

이전 프로젝트에서, SEO를 위해 좀 더 다양한 추가 작업을 할 수 있었음을 알았다. 아쉬운 마음이 들고, 내가 개발한 기능 중 어느 기능에 작업을 할 수 있었는지 개선점을 생각해보아야겠다.
